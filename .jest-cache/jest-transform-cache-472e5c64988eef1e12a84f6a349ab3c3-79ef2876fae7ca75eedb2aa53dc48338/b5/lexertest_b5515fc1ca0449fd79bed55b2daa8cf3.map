{"file":"/workspace/test/lexer.test.ts","mappings":";;AAAA,wCAAqC;AAErC,QAAQ,CAAC,OAAO,EAAE,GAAG,EAAE;IACrB,qDAAqD;IACrD,MAAM,QAAQ,GAAG,CAAC,KAAa,EAAE,EAAE,CAAC,IAAI,aAAK,CAAC,KAAK,CAAC,CAAC,QAAQ,EAAE,CAAC;IAEhE,4DAA4D;IAC5D,MAAM,cAAc,GAAG,CAAC,KAAa,EAAE,EAAE,CACvC,QAAQ,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,CAAC,IAAI,EAAE,KAAK,EAAE,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;IAE3E,QAAQ,CAAC,SAAS,EAAE,GAAG,EAAE;QACvB,IAAI,CAAC,0BAA0B,EAAE,GAAG,EAAE;YACpC,MAAM,MAAM,GAAG,cAAc,CAAC,KAAK,CAAC,CAAC;YACrC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,KAAK,EAAE;gBAChC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,wCAAwC,EAAE,GAAG,EAAE;YAClD,MAAM,MAAM,GAAG,cAAc,CAAC,SAAS,CAAC,CAAC;YACzC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,SAAS,EAAE;gBACpC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,8CAA8C,EAAE,GAAG,EAAE;YACxD,MAAM,MAAM,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;YACxC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,KAAK,EAAE;gBAChC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE;gBACpC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,0DAA0D,EAAE,GAAG,EAAE;YACpE,MAAM,MAAM,GAAG,cAAc,CAAC,MAAM,CAAC,CAAC;YACtC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,KAAK,EAAE;gBAChC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,SAAS,EAAE,GAAG,EAAE;QACvB,IAAI,CAAC,uCAAuC,EAAE,GAAG,EAAE;YACjD,MAAM,MAAM,GAAG,cAAc,CAAC,eAAe,CAAC,CAAC;YAC/C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,aAAa,EAAE;gBACxC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,uCAAuC,EAAE,GAAG,EAAE;YACjD,MAAM,MAAM,GAAG,cAAc,CAAC,eAAe,CAAC,CAAC;YAC/C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,aAAa,EAAE;gBACxC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,6CAA6C,EAAE,GAAG,EAAE;YACvD,MAAM,MAAM,GAAG,cAAc,CAAC,qBAAqB,CAAC,CAAC;YACrD,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,eAAe,EAAE;gBAC1C,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,gCAAgC,EAAE,GAAG,EAAE;YAC1C,MAAM,MAAM,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;YACxC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,kDAAkD,EAAE,GAAG,EAAE;YAC5D,MAAM,MAAM,GAAG,cAAc,CAAC,aAAa,CAAC,CAAC;YAC7C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,SAAS,EAAE;gBACpC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,+CAA+C,EAAE,GAAG,EAAE;YACzD,MAAM,MAAM,GAAG,cAAc,CAAC,UAAU,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,0BAA0B,EAAE,GAAG,EAAE;QACxC,IAAI,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC7C,MAAM,MAAM,GAAG,cAAc,CAAC,UAAU,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,UAAU,EAAE;gBACzC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,0DAA0D,EAAE,GAAG,EAAE;YACpE,MAAM,MAAM,GAAG,cAAc,CAAC,SAAS,CAAC,CAAC;YACzC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,SAAS,EAAE;gBACxC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,2BAA2B,EAAE,GAAG,EAAE;YACrC,MAAM,QAAQ,GAAG,CAAC,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,OAAO,EAAE,IAAI,EAAE,KAAK,EAAE,IAAI,EAAE,YAAY,EAAE,YAAY,EAAE,WAAW,CAAC,CAAC;YAEnL,KAAK,MAAM,OAAO,IAAI,QAAQ,EAAE,CAAC;gBAC/B,MAAM,MAAM,GAAG,cAAc,CAAC,OAAO,CAAC,CAAC;gBACvC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;oBACrB,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE;oBACnC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;iBAC3B,CAAC,CAAC;YACL,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,0CAA0C,EAAE,GAAG,EAAE;YACpD,MAAM,UAAU,GAAG,CAAC,KAAK,EAAE,QAAQ,EAAE,QAAQ,EAAE,MAAM,EAAE,MAAM,CAAC,CAAC;YAE/D,KAAK,MAAM,SAAS,IAAI,UAAU,EAAE,CAAC;gBACnC,MAAM,MAAM,GAAG,cAAc,CAAC,SAAS,CAAC,CAAC;gBACzC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;oBACrB,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,EAAE;oBACrC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;iBAC3B,CAAC,CAAC;YACL,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,iCAAiC,EAAE,GAAG,EAAE;YAC3C,MAAM,MAAM,GAAG,cAAc,CAAC,MAAM,CAAC,CAAC;YACtC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAE,MAAM,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,uCAAuC,EAAE,GAAG,EAAE;YACjD,MAAM,MAAM,GAAG,cAAc,CAAC,KAAK,CAAC,CAAC;YACrC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAE,KAAK,EAAE;gBACjC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,oDAAoD,EAAE,GAAG,EAAE;YAC9D,MAAM,MAAM,GAAG,cAAc,CAAC,UAAU,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,UAAU,EAAE;gBACzC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,WAAW,EAAE,GAAG,EAAE;QACzB,IAAI,CAAC,2CAA2C,EAAE,GAAG,EAAE;YACrD,MAAM,YAAY,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC;YAEtE,KAAK,MAAM,EAAE,IAAI,YAAY,EAAE,CAAC;gBAC9B,MAAM,MAAM,GAAG,cAAc,CAAC,EAAE,CAAC,CAAC;gBAClC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;oBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,EAAE,EAAE;oBAC/B,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;iBAC3B,CAAC,CAAC;YACL,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,4CAA4C,EAAE,GAAG,EAAE;YACtD,MAAM,aAAa,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;YAEpE,KAAK,MAAM,EAAE,IAAI,aAAa,EAAE,CAAC;gBAC/B,MAAM,MAAM,GAAG,cAAc,CAAC,EAAE,CAAC,CAAC;gBAClC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;oBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,EAAE,EAAE;oBAC/B,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;iBAC3B,CAAC,CAAC;YACL,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,qDAAqD,EAAE,GAAG,EAAE;YAC/D,MAAM,MAAM,GAAG,cAAc,CAAC,IAAI,CAAC,CAAC;YACpC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,IAAI,EAAE;gBACjC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,qCAAqC,EAAE,GAAG,EAAE;YAC/C,MAAM,MAAM,GAAG,cAAc,CAAC,MAAM,CAAC,CAAC;YACtC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,kDAAkD,EAAE,GAAG,EAAE;YAC5D,mEAAmE;YACnE,yGAAyG;YACzG,MAAM,MAAM,GAAG,cAAc,CAAC,GAAG,CAAC,CAAC;YACnC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,aAAa,EAAE,GAAG,EAAE;QAC3B,IAAI,CAAC,wCAAwC,EAAE,GAAG,EAAE;YAClD,MAAM,WAAW,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;YAElE,KAAK,MAAM,KAAK,IAAI,WAAW,EAAE,CAAC;gBAChC,MAAM,MAAM,GAAG,cAAc,CAAC,KAAK,CAAC,CAAC;gBACrC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;oBACrB,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,KAAK,EAAE;oBACrC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;iBAC3B,CAAC,CAAC;YACL,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,qCAAqC,EAAE,GAAG,EAAE;YAC/C,MAAM,MAAM,GAAG,cAAc,CAAC,GAAG,CAAC,CAAC;YACnC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,WAAW,EAAE,GAAG,EAAE;QACzB,IAAI,CAAC,gCAAgC,EAAE,GAAG,EAAE;YAC1C,MAAM,MAAM,GAAG,cAAc,CAAC,QAAQ,CAAC,CAAC;YACxC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,OAAO,EAAE;gBACpC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,uDAAuD,EAAE,GAAG,EAAE;YACjE,MAAM,MAAM,GAAG,cAAc,CAAC,YAAY,CAAC,CAAC;YAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,WAAW,EAAE;gBACxC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,8CAA8C,EAAE,GAAG,EAAE;YACxD,MAAM,MAAM,GAAG,cAAc,CAAC,GAAG,CAAC,CAAC;YACnC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,EAAE,EAAE;gBAC/B,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,4CAA4C,EAAE,GAAG,EAAE;YACtD,MAAM,MAAM,GAAG,cAAc,CAAC,IAAI,CAAC,CAAC;YACpC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,EAAE,EAAE;gBAC/B,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,UAAU,EAAE,GAAG,EAAE;QACxB,IAAI,CAAC,kCAAkC,EAAE,GAAG,EAAE;YAC5C,MAAM,gBAAgB,GAAG;;;;;;OAMxB,CAAC;YACF,MAAM,mBAAmB,GAAG;;;;OAI3B,CAAC;YACF,MAAM,kBAAkB,GAAG,IAAI,aAAK,CAAC,gBAAgB,CAAC,CAAC,QAAQ,EAAE,CAAC;YAClE,MAAM,qBAAqB,GAAG,IAAI,aAAK,CAAC,mBAAmB,CAAC,CAAC,QAAQ,EAAE,CAAC;YACxE,sCAAsC;YACtC,MAAM,QAAQ,GAAG,CAAC,CAAM,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC,IAAI,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC;YAChE,MAAM,CAAC,kBAAkB,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,OAAO,CAC9C,qBAAqB,CAAC,GAAG,CAAC,QAAQ,CAAC,CACpC,CAAC;YACF,uCAAuC;YACvC,MAAM,CAAC,kBAAkB,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,IAAI,KAAK,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC3E,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,sCAAsC,EAAE,GAAG,EAAE;YAChD,MAAM,MAAM,GAAG,cAAc,CAAC,aAAa,CAAC,CAAC;YAC7C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,iCAAiC,EAAE,GAAG,EAAE;YAC3C,MAAM,MAAM,GAAG,cAAc,CAAC,2BAA2B,CAAC,CAAC;YAC3D,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,gDAAgD,EAAE,GAAG,EAAE;YAC1D,oEAAoE;YACpE,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,aAAa,CAAC,CAAC;YACvC,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACjC,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,qBAAqB,EAAE,GAAG,EAAE;QACnC,IAAI,CAAC,wBAAwB,EAAE,GAAG,EAAE;YAClC,MAAM,MAAM,GAAG,cAAc,CAAC,kBAAkB,CAAC,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,2BAA2B,EAAE,GAAG,EAAE;YACrC,MAAM,MAAM,GAAG,cAAc,CAAC,EAAE,CAAC,CAAC;YAClC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,+BAA+B,EAAE,GAAG,EAAE;YACzC,MAAM,MAAM,GAAG,cAAc,CAAC,WAAW,CAAC,CAAC;YAC3C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,oBAAoB,EAAE,GAAG,EAAE;QAClC,IAAI,CAAC,iDAAiD,EAAE,GAAG,EAAE;YAC3D,MAAM,MAAM,GAAG,cAAc,CAAC,GAAG,CAAC,CAAC;YACnC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,sDAAsD,EAAE,GAAG,EAAE;YAChE,2CAA2C;YAC3C,MAAM,MAAM,GAAG,cAAc,CAAC,UAAU,CAAC,CAAC,CAAC,qBAAqB;YAChE,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,+DAA+D,EAAE,GAAG,EAAE;YACzE,8FAA8F;YAC9F,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,QAAQ,CAAC,CAAC,CAAC,0CAA0C;YAC7E,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACjC,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,8BAA8B,EAAE,GAAG,EAAE;QAC5C,IAAI,CAAC,yDAAyD,EAAE,GAAG,EAAE;YACnE,sFAAsF;YACtF,0FAA0F;YAC1F,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,WAAW,CAAC,CAAC;YAErC,sBAAsB;YACtB,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YACrC,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAE3C,wEAAwE;YACxE,MAAM,WAAW,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YACtC,MAAM,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACvC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,+DAA+D,EAAE,GAAG,EAAE;YACzE,8EAA8E;YAC9E,kFAAkF;YAClF,qDAAqD;YAErD,qEAAqE;YACrE,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,QAAQ,CAAC,CAAC,CAAC,0BAA0B;YAC7D,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACjC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,yDAAyD,EAAE,GAAG,EAAE;YACnE,wEAAwE;YACxE,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YACtC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAChC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,qDAAqD,EAAE,GAAG,EAAE;YAC/D,gFAAgF;YAChF,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,qBAAqB,CAAC,CAAC,CAAC,gCAAgC;YAChF,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;YACvC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,wDAAwD,EAAE,GAAG,EAAE;YAClE,sFAAsF;YACtF,4EAA4E;YAC5E,0EAA0E;YAC1E,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,OAAO,CAAC,CAAC,CAAC,6BAA6B;YAC/D,MAAM,MAAM,GAAG,QAAQ,CAAC,OAAO,CAAC,CAAC;YACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,2EAA2E,EAAE,GAAG,EAAE;YACrF,kFAAkF;YAClF,MAAM,UAAU,GAAG;gBACjB,QAAQ,EAAE,qBAAqB;gBAC/B,QAAQ,EAAE,mBAAmB;gBAC7B,QAAQ,EAAE,UAAU;gBACpB,QAAQ,EAAE,UAAU;gBACpB,QAAQ,EAAE,WAAW;gBACrB,QAAQ,EAAE,WAAW;gBACrB,QAAQ,EAAE,qBAAqB;gBAC/B,QAAQ,EAAE,oBAAoB;gBAC9B,QAAQ,EAAE,mBAAmB;gBAC7B,QAAQ,EAAE,eAAe;gBACzB,QAAQ,EAAE,oBAAoB;gBAC9B,QAAQ,EAAE,aAAa;gBACvB,QAAQ,EAAE,aAAa;gBACvB,QAAQ,EAAE,wBAAwB;gBAClC,QAAQ,EAAE,4BAA4B;gBACtC,QAAQ,EAAE,oBAAoB;aAC/B,CAAC;YAEF,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,CAAC;gBAC9B,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,IAAI,GAAG,GAAG,CAAC,CAAC;gBACpC,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;gBAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;gBACtC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YAChC,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,8DAA8D,EAAE,GAAG,EAAE;YACxE,2EAA2E;YAC3E,gFAAgF;YAChF,0EAA0E;YAC1E,MAAM,KAAK,GAAG,aAAa,CAAC;YAC5B,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,KAAK,CAAC,CAAC;YAE/B,oBAAoB;YACpB,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YACrC,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAC3C,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YAEnC,4DAA4D;YAC5D,MAAM,WAAW,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YACtC,MAAM,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACvC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,2EAA2E,EAAE,GAAG,EAAE;YACrF,kFAAkF;YAClF,MAAM,KAAK,GAAG,SAAS,CAAC,CAAC,4CAA4C;YACrE,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,0EAA0E,EAAE,GAAG,EAAE;YACpF,4EAA4E;YAC5E,MAAM,KAAK,GAAG,qBAAqB,CAAC,CAAC,6BAA6B;YAClE,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,oEAAoE,EAAE,GAAG,EAAE;YAC9E,sDAAsD;YACtD,MAAM,KAAK,GAAG,KAAK,CAAC;YACpB,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,+DAA+D;YAC/D,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;QAC3C,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,4DAA4D,EAAE,GAAG,EAAE;YACtE,mEAAmE;YACnE,mEAAmE;YACnE,MAAM,KAAK,GAAG,IAAI,CAAC,CAAC,gEAAgE;YACpF,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;YACxC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YAClC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,mDAAmD,EAAE,GAAG,EAAE;YAC7D,0EAA0E;YAC1E,MAAM,KAAK,GAAG,GAAG,CAAC;YAClB,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,kFAAkF,EAAE,GAAG,EAAE;YAC5F,oFAAoF;YACpF,MAAM,KAAK,GAAG,eAAe,CAAC;YAC9B,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;YAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,gEAAgE,EAAE,GAAG,EAAE;YAC1E,8EAA8E;YAC9E,MAAM,KAAK,GAAG,SAAS,CAAC;YACxB,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC;YAC/B,8DAA8D;YAC9D,IAAI,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,YAAY,EAAE,CAAC;gBACpC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACpC,CAAC;iBAAM,CAAC;gBACN,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;YAC7C,CAAC;QACH,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,0BAA0B,EAAE,GAAG,EAAE;QACxC,IAAI,CAAC,wCAAwC,EAAE,GAAG,EAAE;YAClD,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,MAAM,CAAC,CAAC;YAChC,MAAM,MAAM,GAAG,KAAK,CAAC,QAAQ,EAAE,CAAC;YAEhC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC9C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAChD,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAE9C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC9C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAChD,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAChD,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,kCAAkC,EAAE,GAAG,EAAE;YAC5C,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,MAAM,GAAG,KAAK,CAAC,QAAQ,EAAE,CAAC;YAEhC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC9C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAChD,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAChD,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,qBAAqB,EAAE,GAAG,EAAE;QACnC,IAAI,CAAC,oCAAoC,EAAE,GAAG,EAAE;YAC9C,MAAM,MAAM,GAAG,cAAc,CAAC,+CAA+C,CAAC,CAAC;YAC/E,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE;gBAChC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE;gBACpC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,IAAI,EAAE;gBACjC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAE,KAAK,EAAE;gBACjC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,QAAQ,EAAE;gBACvC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE;gBACpC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,GAAG,EAAE;gBAC9B,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,QAAQ,EAAE,KAAK,EAAE,GAAG,EAAE;gBAC9B,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,+CAA+C,EAAE,GAAG,EAAE;YACzD,MAAM,MAAM,GAAG,cAAc,CAAC,eAAe,CAAC,CAAC;YAC/C,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,IAAI,EAAE;gBACjC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,GAAG,EAAE;gBACnC,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,YAAY,EAAE,GAAG,EAAE;QAC1B,IAAI,CAAC,8BAA8B,EAAE,GAAG,EAAE;YACxC,MAAM,KAAK,GAAG,IAAI,aAAK,CAAC,EAAE,CAAC,CAAC;YAC5B,MAAM,KAAK,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;YAChC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC/B,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;QAC/B,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,kDAAkD,EAAE,GAAG,EAAE;YAC5D,MAAM,MAAM,GAAG,cAAc,CAAC,gCAAgC,CAAC,CAAC;YAChE,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,yCAAyC,EAAE,GAAG,EAAE;YACnD,MAAM,MAAM,GAAG,cAAc,CAAC,KAAK,CAAC,CAAC;YACrC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC;gBACrB,EAAE,IAAI,EAAE,YAAY,EAAE,KAAK,EAAE,GAAG,EAAE;gBAClC,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,GAAG,EAAE;gBAChC,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,EAAE;aAC3B,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","names":[],"sources":["/workspace/test/lexer.test.ts"],"sourcesContent":["import { Lexer } from \"../src/lexer\";\n\ndescribe(\"Lexer\", () => {\n  // Helper function to create lexer and get all tokens\n  const tokenize = (input: string) => new Lexer(input).tokenize();\n  \n  // Helper function to get token values without location info\n  const getTokenValues = (input: string) => \n    tokenize(input).map(token => ({ type: token.type, value: token.value }));\n\n  describe(\"Numbers\", () => {\n    test(\"should tokenize integers\", () => {\n      const tokens = getTokenValues(\"123\");\n      expect(tokens).toEqual([\n        { type: \"NUMBER\", value: \"123\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should tokenize floating point numbers\", () => {\n      const tokens = getTokenValues(\"123.456\");\n      expect(tokens).toEqual([\n        { type: \"NUMBER\", value: \"123.456\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should tokenize number followed by non-digit\", () => {\n      const tokens = getTokenValues(\"123abc\");\n      expect(tokens).toEqual([\n        { type: \"NUMBER\", value: \"123\" },\n        { type: \"IDENTIFIER\", value: \"abc\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should not tokenize dot without following digit as float\", () => {\n      const tokens = getTokenValues(\"123.\");\n      expect(tokens).toEqual([\n        { type: \"NUMBER\", value: \"123\" },\n        { type: \"PUNCTUATION\", value: \".\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Strings\", () => {\n    test(\"should tokenize double-quoted strings\", () => {\n      const tokens = getTokenValues('\"hello world\"');\n      expect(tokens).toEqual([\n        { type: \"STRING\", value: \"hello world\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should tokenize single-quoted strings\", () => {\n      const tokens = getTokenValues(\"'hello world'\");\n      expect(tokens).toEqual([\n        { type: \"STRING\", value: \"hello world\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle escaped characters in strings\", () => {\n      const tokens = getTokenValues('\"hello \\\\\"world\\\\\"\"');\n      expect(tokens).toEqual([\n        { type: \"STRING\", value: 'hello \"world\"' },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle unclosed strings\", () => {\n      const tokens = getTokenValues('\"hello');\n      expect(tokens).toEqual([\n        { type: \"STRING\", value: \"hello\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle escaped backslash at end of string\", () => {\n      const tokens = getTokenValues('\"hello\\\\\\\\\"');\n      expect(tokens).toEqual([\n        { type: \"STRING\", value: \"hello\\\\\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle escape sequence at end of input\", () => {\n      const tokens = getTokenValues('\"hello\\\\');\n      expect(tokens).toEqual([\n        { type: \"STRING\", value: \"hello\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Identifiers and Keywords\", () => {\n    test(\"should tokenize basic identifiers\", () => {\n      const tokens = getTokenValues(\"variable\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"variable\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should tokenize identifiers with underscores and numbers\", () => {\n      const tokens = getTokenValues(\"var_123\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"var_123\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should recognize keywords\", () => {\n      const keywords = [\"if\", \"then\", \"else\", \"let\", \"in\", \"fn\", \"import\", \"mut\", \"where\", \"type\", \"match\", \"with\", \"given\", \"is\", \"and\", \"or\", \"implements\", \"constraint\", \"implement\"];\n      \n      for (const keyword of keywords) {\n        const tokens = getTokenValues(keyword);\n        expect(tokens).toEqual([\n          { type: \"KEYWORD\", value: keyword },\n          { type: \"EOF\", value: \"\" }\n        ]);\n      }\n    });\n\n    test(\"should recognize primitive type keywords\", () => {\n      const primitives = [\"Int\", \"Number\", \"String\", \"Unit\", \"List\"];\n      \n      for (const primitive of primitives) {\n        const tokens = getTokenValues(primitive);\n        expect(tokens).toEqual([\n          { type: \"KEYWORD\", value: primitive },\n          { type: \"EOF\", value: \"\" }\n        ]);\n      }\n    });\n\n    test(\"should handle mut! special case\", () => {\n      const tokens = getTokenValues(\"mut!\");\n      expect(tokens).toEqual([\n        { type: \"KEYWORD\", value: \"mut!\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle mut without exclamation\", () => {\n      const tokens = getTokenValues(\"mut\");\n      expect(tokens).toEqual([\n        { type: \"KEYWORD\", value: \"mut\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle identifiers starting with underscore\", () => {\n      const tokens = getTokenValues(\"_private\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"_private\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Operators\", () => {\n    test(\"should tokenize multi-character operators\", () => {\n      const multiCharOps = [\"|>\", \"<|\", \"==\", \"!=\", \"<=\", \">=\", \"=>\", \"->\"];\n      \n      for (const op of multiCharOps) {\n        const tokens = getTokenValues(op);\n        expect(tokens).toEqual([\n          { type: \"OPERATOR\", value: op },\n          { type: \"EOF\", value: \"\" }\n        ]);\n      }\n    });\n\n    test(\"should tokenize single-character operators\", () => {\n      const singleCharOps = [\"+\", \"-\", \"*\", \"/\", \"<\", \">\", \"=\", \"|\", \"$\"];\n      \n      for (const op of singleCharOps) {\n        const tokens = getTokenValues(op);\n        expect(tokens).toEqual([\n          { type: \"OPERATOR\", value: op },\n          { type: \"EOF\", value: \"\" }\n        ]);\n      }\n    });\n\n    test(\"should prefer multi-character operators over single\", () => {\n      const tokens = getTokenValues(\"==\");\n      expect(tokens).toEqual([\n        { type: \"OPERATOR\", value: \"==\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle operators in sequence\", () => {\n      const tokens = getTokenValues(\"+-*/\");\n      expect(tokens).toEqual([\n        { type: \"OPERATOR\", value: \"+\" },\n        { type: \"OPERATOR\", value: \"-\" },\n        { type: \"OPERATOR\", value: \"*\" },\n        { type: \"OPERATOR\", value: \"/\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle single character operator fallback\", () => {\n      // Test the fallback case where no multi-character operator matches\n      // This specifically tests line 224 by using \"!\" which matches the regex but isn't in the multi-char list\n      const tokens = getTokenValues(\"!\");\n      expect(tokens).toEqual([\n        { type: \"OPERATOR\", value: \"!\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Punctuation\", () => {\n    test(\"should tokenize punctuation characters\", () => {\n      const punctuation = [\"(\", \")\", \",\", \";\", \":\", \"[\", \"]\", \"{\", \"}\"];\n      \n      for (const punct of punctuation) {\n        const tokens = getTokenValues(punct);\n        expect(tokens).toEqual([\n          { type: \"PUNCTUATION\", value: punct },\n          { type: \"EOF\", value: \"\" }\n        ]);\n      }\n    });\n\n    test(\"should handle period as punctuation\", () => {\n      const tokens = getTokenValues(\".\");\n      expect(tokens).toEqual([\n        { type: \"PUNCTUATION\", value: \".\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Accessors\", () => {\n    test(\"should tokenize basic accessor\", () => {\n      const tokens = getTokenValues(\"@field\");\n      expect(tokens).toEqual([\n        { type: \"ACCESSOR\", value: \"field\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should tokenize accessor with numbers and underscores\", () => {\n      const tokens = getTokenValues(\"@field_123\");\n      expect(tokens).toEqual([\n        { type: \"ACCESSOR\", value: \"field_123\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle @ without following identifier\", () => {\n      const tokens = getTokenValues(\"@\");\n      expect(tokens).toEqual([\n        { type: \"ACCESSOR\", value: \"\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle @ followed by non-identifier\", () => {\n      const tokens = getTokenValues(\"@(\");\n      expect(tokens).toEqual([\n        { type: \"ACCESSOR\", value: \"\" },\n        { type: \"PUNCTUATION\", value: \"(\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Comments\", () => {\n    test(\"should skip single-line comments\", () => {\n      const codeWithComments = `\n        # this is a comment\n        x = 5 # inline comment\n        y = 10\n        # another comment\n        x + y # trailing comment\n      `;\n      const codeWithoutComments = `\n        x = 5\n        y = 10\n        x + y\n      `;\n      const tokensWithComments = new Lexer(codeWithComments).tokenize();\n      const tokensWithoutComments = new Lexer(codeWithoutComments).tokenize();\n      // Remove location info for comparison\n      const stripLoc = (t: any) => ({ type: t.type, value: t.value });\n      expect(tokensWithComments.map(stripLoc)).toEqual(\n        tokensWithoutComments.map(stripLoc),\n      );\n      // Ensure no COMMENT tokens are present\n      expect(tokensWithComments.some((t) => t.type === \"COMMENT\")).toBe(false);\n    });\n\n    test(\"should handle comment at end of file\", () => {\n      const tokens = getTokenValues(\"x # comment\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle multiple comments\", () => {\n      const tokens = getTokenValues(\"# comment1\\n# comment2\\nx\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle comment encountered in nextToken\", () => {\n      // This tests the comment handling path in nextToken (lines 317-319)\n      const lexer = new Lexer(\"# comment\\n\");\n      const token = lexer.nextToken();\n      expect(token.type).toBe(\"EOF\");\n    });\n  });\n\n  describe(\"Whitespace handling\", () => {\n    test(\"should skip whitespace\", () => {\n      const tokens = getTokenValues(\"  \\t  x  \\n  y  \");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"IDENTIFIER\", value: \"y\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle empty input\", () => {\n      const tokens = getTokenValues(\"\");\n      expect(tokens).toEqual([\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle whitespace only\", () => {\n      const tokens = getTokenValues(\"   \\t\\n  \");\n      expect(tokens).toEqual([\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Unknown characters\", () => {\n    test(\"should handle unknown characters as punctuation\", () => {\n      const tokens = getTokenValues(\"~\");\n      expect(tokens).toEqual([\n        { type: \"PUNCTUATION\", value: \"~\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle unknown characters that are whitespace\", () => {\n      // Test with a Unicode whitespace character\n      const tokens = getTokenValues(\"x\\u00A0y\"); // Non-breaking space\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"IDENTIFIER\", value: \"y\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle unknown whitespace characters in nextToken path\", () => {\n      // This tests line 327 - when unknown character is whitespace and triggers recursive nextToken\n      const lexer = new Lexer(\"\\u00A0\"); // Non-breaking space as unknown character\n      const token = lexer.nextToken();\n      expect(token.type).toBe(\"EOF\");\n    });\n  });\n\n  describe(\"Edge cases for 100% coverage\", () => {\n    test(\"should handle comment in nextToken path (lines 317-319)\", () => {\n      // This is tricky - we need a scenario where skipWhitespace doesn't handle the comment\n      // Let's create a scenario where the lexer position is at a comment after other processing\n      const lexer = new Lexer(\"x#comment\");\n      \n      // Get first token (x)\n      const firstToken = lexer.nextToken();\n      expect(firstToken.type).toBe(\"IDENTIFIER\");\n      \n      // Now position should be at the comment, and nextToken should handle it\n      const secondToken = lexer.nextToken();\n      expect(secondToken.type).toBe(\"EOF\");\n    });\n\n    test(\"should handle whitespace in unknown character path (line 327)\", () => {\n      // Create a test where an unknown character becomes whitespace after advance()\n      // This happens when we have a character that doesn't match any category initially\n      // but when advanced and checked again, is whitespace\n      \n      // Use a Unicode character that might be treated as unknown initially\n      const lexer = new Lexer(\"\\u2000\"); // EN QUAD - Unicode space\n      const token = lexer.nextToken();\n      expect(token.type).toBe(\"EOF\");\n    });\n\n    test(\"should handle form feed as potential unknown whitespace\", () => {\n      // Form feed (\\f) might trigger the unknown character path in some cases\n      const lexer = new Lexer(\"\\fx\");\n      const token = lexer.nextToken();\n      expect(token.type).toBe(\"IDENTIFIER\");\n      expect(token.value).toBe(\"x\");\n    });\n\n    test(\"should handle zero-width space as unknown character\", () => {\n      // Zero-width characters are treated as punctuation, not whitespace by the lexer\n      const lexer = new Lexer(\"\\u200B\\u200C\\u200Dx\"); // Various zero-width characters\n      const token = lexer.nextToken();\n      expect(token.type).toBe(\"PUNCTUATION\");\n      expect(token.value).toBe(\"\\u200B\");\n    });\n\n    test(\"should handle tab character in unknown path (line 327)\", () => {\n      // This test specifically targets line 327 - unknown character that becomes whitespace\n      // We need a character that doesn't match initial patterns but is whitespace\n      // Let's try a form feed character or vertical tab that might slip through\n      const lexer = new Lexer(\"\\v\\fx\"); // vertical tab and form feed\n      const tokens = tokenize(\"\\v\\fx\");\n      expect(tokens[0].type).toBe(\"IDENTIFIER\");\n      expect(tokens[0].value).toBe(\"x\");\n    });\n\n    test(\"should handle specific Unicode whitespace that might be unknown initially\", () => {\n      // Test with various Unicode whitespace characters that might not match initial \\s\n      const characters = [\n        \"\\u00A0\", // Non-breaking space\n        \"\\u1680\", // Ogham space mark\n        \"\\u2000\", // En quad\n        \"\\u2001\", // Em quad\n        \"\\u2002\", // En space\n        \"\\u2003\", // Em space\n        \"\\u2004\", // Three-per-em space\n        \"\\u2005\", // Four-per-em space\n        \"\\u2006\", // Six-per-em space\n        \"\\u2007\", // Figure space\n        \"\\u2008\", // Punctuation space\n        \"\\u2009\", // Thin space\n        \"\\u200A\", // Hair space\n        \"\\u202F\", // Narrow no-break space\n        \"\\u205F\", // Medium mathematical space\n        \"\\u3000\", // Ideographic space\n      ];\n\n      for (const char of characters) {\n        const lexer = new Lexer(char + \"x\");\n        const token = lexer.nextToken();\n        expect(token.type).toBe(\"IDENTIFIER\");\n        expect(token.value).toBe(\"x\");\n      }\n    });\n\n    test(\"should trigger comment fallback in nextToken (lines 317-319)\", () => {\n      // Try to create a scenario where skipWhitespace doesn't handle the comment\n      // This is a very specific edge case - create a lexer where we manually position\n      // it so that skipWhitespace has already been called but a comment appears\n      const input = \"a\\t#comment\";\n      const lexer = new Lexer(input);\n      \n      // Get the 'a' token\n      const firstToken = lexer.nextToken();\n      expect(firstToken.type).toBe(\"IDENTIFIER\");\n      expect(firstToken.value).toBe(\"a\");\n      \n      // The next token should skip the tab and handle the comment\n      const secondToken = lexer.nextToken();\n      expect(secondToken.type).toBe(\"EOF\");\n    });\n\n    test(\"should trigger unknown whitespace path (line 327) with non-breaking space\", () => {\n      // Use a non-breaking space which might not be caught by initial whitespace checks\n      const input = \"\\u00A0x\"; // Non-breaking space followed by identifier\n      const tokens = tokenize(input);\n      expect(tokens[0].type).toBe(\"IDENTIFIER\");\n      expect(tokens[0].value).toBe(\"x\");\n    });\n\n    test(\"should trigger unknown whitespace path (line 327) with exotic whitespace\", () => {\n      // Try other Unicode whitespace characters that might not match initial /\\s/\n      const input = \"\\u2000\\u2001\\u2002x\"; // En quad, Em quad, En space\n      const tokens = tokenize(input);\n      expect(tokens[0].type).toBe(\"IDENTIFIER\");\n      expect(tokens[0].value).toBe(\"x\");\n    });\n\n    test(\"should trigger exact uncovered paths with null character edge case\", () => {\n      // Try a null character that might behave unexpectedly\n      const input = \"\\0x\";\n      const tokens = tokenize(input);\n      // This should either handle the null as punctuation or skip it\n      expect(tokens.length).toBeGreaterThan(0);\n    });\n\n    test(\"should handle character that looks like operator but isn't\", () => {\n      // Try to trigger the single character operator fallback (line 224)\n      // Use a character that matches operator regex but isn't multi-char\n      const input = \"!x\"; // ! is in the operator regex and not multi-char in this context\n      const tokens = tokenize(input);\n      expect(tokens[0].type).toBe(\"OPERATOR\");\n      expect(tokens[0].value).toBe(\"!\");\n      expect(tokens[1].type).toBe(\"IDENTIFIER\");\n      expect(tokens[1].value).toBe(\"x\");\n    });\n\n    test(\"should handle comment immediately after EOF check\", () => {\n      // Try to create a scenario where comment handling hits the nextToken path\n      const input = \"#\";\n      const tokens = tokenize(input);\n      expect(tokens[0].type).toBe(\"EOF\");\n    });\n\n    test(\"should handle edge case for exact line coverage - carriage return before comment\", () => {\n      // Try using carriage return which might not be handled the same as other whitespace\n      const input = \"\\r#comment\\nx\";\n      const tokens = tokenize(input);\n      expect(tokens[0].type).toBe(\"IDENTIFIER\");\n      expect(tokens[0].value).toBe(\"x\");\n    });\n\n    test(\"should handle zero-width joiner that might not match \\\\s regex\", () => {\n      // Zero-width joiner (U+200D) might not match \\\\s but could be whitespace-like\n      const input = \"\\u200Dx\";\n      const tokens = tokenize(input);\n      // This should either skip the ZWJJ or treat it as punctuation\n      if (tokens[0].type === \"IDENTIFIER\") {\n        expect(tokens[0].value).toBe(\"x\");\n      } else {\n        expect(tokens[0].type).toBe(\"PUNCTUATION\");\n      }\n    });\n  });\n\n  describe(\"Line and column tracking\", () => {\n    test(\"should track line and column positions\", () => {\n      const lexer = new Lexer(\"x\\ny\");\n      const tokens = lexer.tokenize();\n      \n      expect(tokens[0].location.start.line).toBe(1);\n      expect(tokens[0].location.start.column).toBe(1);\n      expect(tokens[0].location.end.line).toBe(1);\n      expect(tokens[0].location.end.column).toBe(2);\n      \n      expect(tokens[1].location.start.line).toBe(2);\n      expect(tokens[1].location.start.column).toBe(1);\n      expect(tokens[1].location.end.line).toBe(2);\n      expect(tokens[1].location.end.column).toBe(2);\n    });\n\n    test(\"should handle column advancement\", () => {\n      const lexer = new Lexer(\"abc\");\n      const tokens = lexer.tokenize();\n      \n      expect(tokens[0].location.start.line).toBe(1);\n      expect(tokens[0].location.start.column).toBe(1);\n      expect(tokens[0].location.end.line).toBe(1);\n      expect(tokens[0].location.end.column).toBe(4);\n    });\n  });\n\n  describe(\"Complex expressions\", () => {\n    test(\"should tokenize complex expression\", () => {\n      const tokens = getTokenValues('fn add(x, y) -> x + y\\nlet result = add(1, 2)');\n      expect(tokens).toEqual([\n        { type: \"KEYWORD\", value: \"fn\" },\n        { type: \"IDENTIFIER\", value: \"add\" },\n        { type: \"PUNCTUATION\", value: \"(\" },\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"PUNCTUATION\", value: \",\" },\n        { type: \"IDENTIFIER\", value: \"y\" },\n        { type: \"PUNCTUATION\", value: \")\" },\n        { type: \"OPERATOR\", value: \"->\" },\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"OPERATOR\", value: \"+\" },\n        { type: \"IDENTIFIER\", value: \"y\" },\n        { type: \"KEYWORD\", value: \"let\" },\n        { type: \"IDENTIFIER\", value: \"result\" },\n        { type: \"OPERATOR\", value: \"=\" },\n        { type: \"IDENTIFIER\", value: \"add\" },\n        { type: \"PUNCTUATION\", value: \"(\" },\n        { type: \"NUMBER\", value: \"1\" },\n        { type: \"PUNCTUATION\", value: \",\" },\n        { type: \"NUMBER\", value: \"2\" },\n        { type: \"PUNCTUATION\", value: \")\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle mixed operators and punctuation\", () => {\n      const tokens = getTokenValues(\"(x == y) && z\");\n      expect(tokens).toEqual([\n        { type: \"PUNCTUATION\", value: \"(\" },\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"OPERATOR\", value: \"==\" },\n        { type: \"IDENTIFIER\", value: \"y\" },\n        { type: \"PUNCTUATION\", value: \")\" },\n        { type: \"PUNCTUATION\", value: \"&\" },\n        { type: \"PUNCTUATION\", value: \"&\" },\n        { type: \"IDENTIFIER\", value: \"z\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n\n  describe(\"Edge cases\", () => {\n    test(\"should handle EOF conditions\", () => {\n      const lexer = new Lexer(\"\");\n      const token = lexer.nextToken();\n      expect(token.type).toBe(\"EOF\");\n      expect(token.value).toBe(\"\");\n    });\n\n    test(\"should handle sequential whitespace and comments\", () => {\n      const tokens = getTokenValues(\"  # comment\\n  \\t# another\\n x\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n\n    test(\"should handle operators at end of input\", () => {\n      const tokens = getTokenValues(\"x +\");\n      expect(tokens).toEqual([\n        { type: \"IDENTIFIER\", value: \"x\" },\n        { type: \"OPERATOR\", value: \"+\" },\n        { type: \"EOF\", value: \"\" }\n      ]);\n    });\n  });\n});\n"],"version":3}